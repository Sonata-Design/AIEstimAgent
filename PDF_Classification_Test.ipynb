{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF Page Classification Test\n",
    "\n",
    "Test the PDF processing and classification system in Google Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get update\n",
    "!apt-get install -y tesseract-ocr poppler-utils\n",
    "!pip install pdf2image PyPDF2 pytesseract pillow numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Upload Your PDF\n",
    "\n",
    "Click the folder icon on the left, then upload your PDF file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "# Upload PDF\n",
    "print(\"Please upload your PDF file:\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Get the uploaded filename\n",
    "pdf_filename = list(uploaded.keys())[0]\n",
    "print(f\"\\n‚úÖ Uploaded: {pdf_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. PDF Processor Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "import PyPDF2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from typing import Dict, List\n",
    "\n",
    "class PDFProcessor:\n",
    "    def __init__(self):\n",
    "        self.page_types = [\n",
    "            'floor_plan', 'elevation', 'section',\n",
    "            'electrical_plan', 'plumbing_plan', 'hvac_plan',\n",
    "            'site_plan', 'detail', 'notes', 'cover_page',\n",
    "            'schedule', 'unknown'\n",
    "        ]\n",
    "    \n",
    "    def process_pdf(self, pdf_path: str, output_dir: str = '/content/output') -> Dict:\n",
    "        \"\"\"Process PDF and classify each page\"\"\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Get total pages\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            pdf_reader = PyPDF2.PdfReader(file)\n",
    "            total_pages = len(pdf_reader.pages)\n",
    "        \n",
    "        print(f\"\\nüìÑ Converting {total_pages} pages to images...\")\n",
    "        \n",
    "        # Convert PDF to images\n",
    "        images = convert_from_path(pdf_path, dpi=300, fmt='jpeg')\n",
    "        \n",
    "        # Process each page\n",
    "        pages_data = []\n",
    "        \n",
    "        for i, image in enumerate(images):\n",
    "            page_num = i + 1\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"üìÑ Processing Page {page_num}/{total_pages}\")\n",
    "            print(f\"{'='*60}\")\n",
    "            \n",
    "            # Save image\n",
    "            image_path = os.path.join(output_dir, f'page_{page_num}.jpg')\n",
    "            image.save(image_path, 'JPEG', quality=95)\n",
    "            \n",
    "            # Classify page\n",
    "            classification = self._classify_page(image_path, image)\n",
    "            \n",
    "            pages_data.append({\n",
    "                'page_number': page_num,\n",
    "                'type': classification['type'],\n",
    "                'confidence': classification['confidence'],\n",
    "                'title': classification['title'],\n",
    "                'analyzable': classification['analyzable'],\n",
    "                'metadata': classification.get('metadata', {})\n",
    "            })\n",
    "            \n",
    "            # Display results\n",
    "            print(f\"\\n‚úÖ Classification Result:\")\n",
    "            print(f\"   Type: {classification['type']}\")\n",
    "            print(f\"   Title: {classification['title']}\")\n",
    "            print(f\"   Analyzable: {'‚úÖ YES' if classification['analyzable'] else '‚ùå NO'}\")\n",
    "            print(f\"   Confidence: {classification['confidence']:.2f}\")\n",
    "            \n",
    "            # Show thumbnail\n",
    "            thumbnail = image.copy()\n",
    "            thumbnail.thumbnail((200, 200))\n",
    "            display(thumbnail)\n",
    "        \n",
    "        return {\n",
    "            'total_pages': total_pages,\n",
    "            'pages': pages_data\n",
    "        }\n",
    "    \n",
    "    def _classify_page(self, image_path: str, image: Image.Image) -> Dict:\n",
    "        \"\"\"Classify a single page\"\"\"\n",
    "        \n",
    "        # Extract text with OCR\n",
    "        print(\"\\nüîç Extracting text with OCR...\")\n",
    "        text = pytesseract.image_to_string(image)\n",
    "        text_lower = text.lower()\n",
    "        word_count = len(text.split())\n",
    "        \n",
    "        print(f\"   Words extracted: {word_count}\")\n",
    "        if word_count > 0:\n",
    "            preview = text[:150].replace('\\n', ' ')\n",
    "            print(f\"   Text preview: {preview}...\")\n",
    "        \n",
    "        # Analyze image\n",
    "        print(\"\\nüñºÔ∏è Analyzing image properties...\")\n",
    "        img_array = np.array(image)\n",
    "        height, width = img_array.shape[:2]\n",
    "        aspect_ratio = width / height\n",
    "        \n",
    "        # Drawing detection\n",
    "        is_drawing = self._looks_like_drawing(img_array)\n",
    "        \n",
    "        print(f\"   Aspect ratio: {aspect_ratio:.2f}\")\n",
    "        print(f\"   Looks like drawing: {'‚úÖ YES' if is_drawing else '‚ùå NO'}\")\n",
    "        \n",
    "        # Classification logic\n",
    "        page_type = 'unknown'\n",
    "        confidence = 0.5\n",
    "        title = \"Unknown Page\"\n",
    "        analyzable = False\n",
    "        \n",
    "        # Text-heavy pages\n",
    "        if word_count > 100:\n",
    "            if any(kw in text_lower for kw in ['note', 'specification', 'general', 'description']):\n",
    "                page_type = 'notes'\n",
    "                title = \"Notes & Specifications\"\n",
    "                analyzable = False\n",
    "                confidence = 0.85\n",
    "            elif any(kw in text_lower for kw in ['schedule', 'finish', 'door', 'window', 'room']):\n",
    "                page_type = 'schedule'\n",
    "                title = \"Schedule\"\n",
    "                analyzable = False\n",
    "                confidence = 0.80\n",
    "        \n",
    "        # Drawing pages\n",
    "        else:\n",
    "            # Check for keywords\n",
    "            if any(kw in text_lower for kw in ['floor plan', 'plan view', 'first floor', 'second floor']):\n",
    "                page_type = 'floor_plan'\n",
    "                title = \"Floor Plan\"\n",
    "                analyzable = True\n",
    "                confidence = 0.90\n",
    "            elif any(kw in text_lower for kw in ['elevation', 'front elevation', 'side elevation']):\n",
    "                page_type = 'elevation'\n",
    "                title = \"Elevation\"\n",
    "                analyzable = True\n",
    "                confidence = 0.90\n",
    "            elif any(kw in text_lower for kw in ['electrical', 'power', 'lighting']):\n",
    "                page_type = 'electrical_plan'\n",
    "                title = \"Electrical Plan\"\n",
    "                analyzable = True\n",
    "                confidence = 0.85\n",
    "            # Use image analysis\n",
    "            elif is_drawing or word_count < 100:\n",
    "                page_type = 'floor_plan'\n",
    "                title = \"Floor Plan (Auto-detected)\"\n",
    "                analyzable = True\n",
    "                confidence = 0.55 if is_drawing else 0.50\n",
    "        \n",
    "        return {\n",
    "            'type': page_type,\n",
    "            'confidence': confidence,\n",
    "            'title': title,\n",
    "            'analyzable': analyzable,\n",
    "            'metadata': {\n",
    "                'word_count': word_count,\n",
    "                'aspect_ratio': aspect_ratio,\n",
    "                'is_drawing': is_drawing\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def _looks_like_drawing(self, img_array: np.ndarray) -> bool:\n",
    "        \"\"\"Detect if image looks like an architectural drawing\"\"\"\n",
    "        try:\n",
    "            # Convert to grayscale\n",
    "            if len(img_array.shape) == 3:\n",
    "                gray = np.mean(img_array, axis=2).astype(np.uint8)\n",
    "            else:\n",
    "                gray = img_array.astype(np.uint8)\n",
    "            \n",
    "            # Calculate statistics\n",
    "            height, width = gray.shape\n",
    "            total_pixels = height * width\n",
    "            \n",
    "            avg_brightness = np.mean(gray)\n",
    "            brightness_std = np.std(gray)\n",
    "            dark_pixels = np.sum(gray < 200)\n",
    "            dark_ratio = dark_pixels / total_pixels\n",
    "            \n",
    "            # Drawing characteristics\n",
    "            mostly_white = avg_brightness > 200\n",
    "            has_content = dark_ratio > 0.05\n",
    "            has_contrast = brightness_std > 30\n",
    "            \n",
    "            is_drawing = mostly_white and has_content and has_contrast\n",
    "            \n",
    "            print(f\"   Brightness: {avg_brightness:.1f}\")\n",
    "            print(f\"   Dark pixel ratio: {dark_ratio:.3f}\")\n",
    "            print(f\"   Contrast (std): {brightness_std:.1f}\")\n",
    "            \n",
    "            return is_drawing\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è Drawing detection failed: {e}\")\n",
    "            return False\n",
    "\n",
    "print(\"‚úÖ PDFProcessor class loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Process the PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create processor\n",
    "processor = PDFProcessor()\n",
    "\n",
    "# Process PDF\n",
    "result = processor.process_pdf(pdf_filename)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total pages: {result['total_pages']}\")\n",
    "\n",
    "analyzable_count = sum(1 for p in result['pages'] if p['analyzable'])\n",
    "print(f\"Analyzable pages: {analyzable_count}\")\n",
    "print(f\"Not analyzable: {result['total_pages'] - analyzable_count}\")\n",
    "\n",
    "print(\"\\nüìã Page Details:\")\n",
    "for page in result['pages']:\n",
    "    status = \"‚úÖ ANALYZABLE\" if page['analyzable'] else \"‚ùå NOT ANALYZABLE\"\n",
    "    print(f\"  Page {page['page_number']}: {page['title']} - {status} ({page['confidence']:.0%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Detailed Analysis of Each Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create DataFrame for analysis\n",
    "df_data = []\n",
    "for page in result['pages']:\n",
    "    df_data.append({\n",
    "        'Page': page['page_number'],\n",
    "        'Type': page['type'],\n",
    "        'Title': page['title'],\n",
    "        'Analyzable': '‚úÖ' if page['analyzable'] else '‚ùå',\n",
    "        'Confidence': f\"{page['confidence']:.0%}\",\n",
    "        'Words': page['metadata'].get('word_count', 0),\n",
    "        'Is Drawing': '‚úÖ' if page['metadata'].get('is_drawing', False) else '‚ùå',\n",
    "        'Aspect Ratio': f\"{page['metadata'].get('aspect_ratio', 0):.2f}\"\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(df_data)\n",
    "print(\"\\nüìä Detailed Page Analysis:\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test Individual Page\n",
    "\n",
    "If you want to test a specific page in detail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this to test a specific page\n",
    "test_page_number = 1\n",
    "\n",
    "image_path = f'/content/output/page_{test_page_number}.jpg'\n",
    "image = Image.open(image_path)\n",
    "\n",
    "print(f\"Testing Page {test_page_number}:\")\n",
    "classification = processor._classify_page(image_path, image)\n",
    "\n",
    "print(f\"\\n‚úÖ Result:\")\n",
    "print(f\"   Type: {classification['type']}\")\n",
    "print(f\"   Analyzable: {classification['analyzable']}\")\n",
    "print(f\"   Confidence: {classification['confidence']:.2f}\")\n",
    "\n",
    "# Show image\n",
    "display(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
